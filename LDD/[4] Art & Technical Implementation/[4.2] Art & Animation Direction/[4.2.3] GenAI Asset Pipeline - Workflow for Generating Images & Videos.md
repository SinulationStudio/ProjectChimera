<!-- Filename: LDD/[4] Art & Technical Implementation/[4.2] Art & Animation Direction/[4.2.3] GenAI Asset Pipeline - Workflow for Generating Images & Videos.md -->

# [4.2.3] GenAI Asset Pipeline - Workflow for Generating Images & Videos

This document outlines the planned workflow for creating the game's visual assets using a suite of Generative AI tools. The goal is to establish a consistent, efficient pipeline for producing high-quality 2D art and short video animations that adhere to our established "Stylized Realism" art direction.

## Core Principle: A Multi-Tool, Iterative Approach
We will not rely on a single AI model. The pipeline will involve using the best specialized tool for each task (static images, video animation) and iterating extensively to achieve the desired quality and consistency. The prompts and guidelines defined in the **`[2.4.5] Master Card List`** will serve as the foundation for this process.

---

## Stage 1: Static Image Generation (Card Art, Character Portraits, Backgrounds)

*   **Primary Tool:** Image generation models known for high detail and style control. The initial target model is **Illustrious**, but this is flexible based on the state of the art. Other models like Stable Diffusion (with custom LoRAs) or Midjourney are viable alternatives.
*   **Workflow:**
    1.  **Prompt Construction:** Prompts will be built using the Danbooru tag-based system, as it provides granular control over character features, poses, clothing, and composition. The "Card Design Constitution" will be strictly followed.
    2.  **Character Consistency:** To ensure characters like Analyst Sarah look consistent across multiple images, we will employ techniques such as:
        *   Using a highly detailed descriptive prompt for her core features (`(white hair:1.2), short hair, green eyes, glasses, sharp chin...`).
        *   Potentially training a character-specific **LoRA (Low-Rank Adaptation)** on a set of curated base images to enforce consistency.
    3.  **Asset Generation:** We will generate a base "portrait" for each character, and then generate variations for different states (`Inhibition` thresholds, emotional reactions) by modifying the prompt with tags like `topless`, `nude`, `(smirk:1.2)`, `(crying:1.1)`, etc.

## Stage 2: Animation Generation (Cinematic Turns)

*   **Primary Tool:** Image-to-Video or Text-to-Video AI models. The initial target model is **WAN 2.1**, with alternatives like Runway Gen-2 or Pika Labs as backup.
*   **Workflow (Image-to-Video):**
    1.  **Source Image:** A high-quality static image generated in Stage 1 will be used as the starting frame.
    2.  **Conversational Prompting:** A clear, direct, conversational prompt will describe the desired motion. The prompt will be specific and concise to generate short (2-6 second) video clips.
        *   *Example Prompt:* "From this image, make the woman's eyes widen slightly. She should have a visible shiver run through her shoulders, and her breath should hitch. A very short, sharp, reactive animation."
    3.  **FPV Focus:** A significant portion of animations will be from a First-Person View. We will leverage models and techniques specifically trained on POV content to achieve the best results.
    4.  **Post-Processing:** Generated video clips will likely require editing in standard video software to trim, color correct, and ensure seamless looping where necessary.

## Stage 3: UI & Asset Integration

*   **Engine:** Godot Engine.
*   **Workflow:**
    1.  Generated static images (`.png`) for backgrounds, character sprites, and card art will be imported directly into the Godot project.
    2.  Generated video clips will be converted to the efficient `.webm` format before being imported.
    3.  Godot's `AnimationPlayer` and `VideoPlayer` nodes will be used to trigger these assets at the appropriate moments during gameplay, as defined by our card and ability designs.

This pipeline allows for the rapid creation and iteration of high-quality, custom visual assets, enabling a solo developer to achieve a level of visual polish that would be impossible with traditional methods.

---
| | [â–² Return to Table of Contents](../../README.md) | |
| :--- | :---: | ---: |